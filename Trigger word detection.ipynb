{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import librosa.display\n",
    "from td_utils import *\n",
    "%matplotlib inline\n",
    "\n",
    "audio_dir = os.path.join('.','data','train_audios')\n",
    "wav_file = 'mix_0.wav'\n",
    "fullname = os.path.join(audio_dir, wav_file)\n",
    "\n",
    "x = graph_spectrogram(fullname)\n",
    "_, data = get_wav_info(fullname)\n",
    "print(\"Time steps in audio recording before spectrogram\", data.shape)\n",
    "print(\"Time steps in input after spectrogram\", x.shape)\n",
    "\n",
    "librosa.display.specshow(x, sr=44100, x_axis='time', y_axis='mel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.shape\n",
    "Tx = x.shape[1]     # 스펙토그램 길이\n",
    "n_freq = x.shape[0] # 스펙토그램 높이\n",
    "Ty = 1375           # 아웃풋 길이"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DataLoader\n",
    "\n",
    "with keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.utils import Sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join('.','data','XY_train')\n",
    "x_s = []\n",
    "y_s = []\n",
    "for file in os.listdir(data_dir):\n",
    "    if file.startswith('x_'):\n",
    "        x_s.append(os.path.join(data_dir,file))\n",
    "    elif file.startswith('y_'):\n",
    "        y_s.append(os.path.join(data_dir,file))\n",
    "    x_s = sorted(x_s)\n",
    "    y_s = sorted(y_s)\n",
    "df = pd.DataFrame({'x':x_s, 'y':y_s})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.8\n",
    "idxs = list(range(len(df)))\n",
    "np.random.shuffle(idxs)\n",
    "train_idx = idxs[:int(len(df)*train_ratio)]\n",
    "text_idx = idxs[int(len(df)*train_ratio):]\n",
    "\n",
    "train_df = df.loc[train_idx]\n",
    "test_df = df.loc[text_idx]\n",
    "\n",
    "print(train_df.shape, test_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DataGenerator(Sequence):\n",
    "    def __init__(self, df, batch_size, shuffle = True):\n",
    "        self.X = list(df.x)\n",
    "        self.y = list(df.y)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.on_epoch_end()\n",
    "        \n",
    "    def on_epoch_end(self):\n",
    "        self.indexes = np.arange(len(self.X))\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "            \n",
    "    def __len__(self):\n",
    "        return int(np.floor(len(self.X) / self.batch_size))\n",
    "    \n",
    "    def __data_generation(self, X_list, y_list):\n",
    "        X = []\n",
    "        y = []\n",
    "        for i, (img, label) in enumerate(zip(X_list, y_list)):\n",
    "            X.append(np.load(img))\n",
    "            y.append(np.load(label))\n",
    "        \n",
    "        X = np.stack(X, axis=0)\n",
    "        y = np.stack(y, axis=0)\n",
    "\n",
    "        return X, y\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        indexes = self.indexes[index * self.batch_size : (index + 1) * self.batch_size]\n",
    "        X_list = [self.X[k] for k in indexes]\n",
    "        y_list = [self.y[k] for k in indexes]\n",
    "        X, y = self.__data_generation(X_list, y_list)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = DataGenerator(train_df, 5)\n",
    "test_generator = DataGenerator(test_df, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.models import Model, load_model, Sequential\n",
    "from keras.layers import Dense, Activation, Dropout, Input, Masking, TimeDistributed, LSTM, Conv1D\n",
    "from keras.layers import GRU, Bidirectional, BatchNormalization, Reshape\n",
    "from keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_model(input_shape):\n",
    "    \n",
    "    X_input = Input(shape = input_shape)\n",
    "    X = Conv1D(196, kernel_size=15, strides=4)(X_input)         # CONV1D\n",
    "    X = BatchNormalization()(X)                                 # Batch normalization\n",
    "    X = Activation('relu')(X)                                   # ReLu activation\n",
    "    X = Dropout(0.8)(X)                                         # dropout (use 0.8)\n",
    "\n",
    "    X = GRU(units = 128, return_sequences = True)(X)            # GRU (use 128 units and return the sequences)\n",
    "    X = Dropout(0.8)(X)                                         # dropout (use 0.8)\n",
    "    X = BatchNormalization()(X)                                 # Batch normalization\n",
    "\n",
    "    X = GRU(units = 128, return_sequences = True)(X)            # GRU (use 128 units and return the sequences)\n",
    "    X = Dropout(0.8)(X)                                         # dropout (use 0.8)\n",
    "    X = BatchNormalization()(X)                                 # Batch normalization\n",
    "    X = Dropout(0.8)(X)                                         # dropout (use 0.8)\n",
    "\n",
    "    X = TimeDistributed(Dense(1, activation = \"sigmoid\"))(X)    # time distributed  (sigmoid)\n",
    "\n",
    "    model = Model(inputs = X_input, outputs = X)\n",
    "    return model  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = make_model(input_shape = (Tx, n_freq))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = Adam(lr=0.0001, beta_1=0.9, beta_2=0.999, decay=0.01)\n",
    "model.compile(loss='binary_crossentropy', optimizer=opt, metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.fit_generator(generator=train_generator,\n",
    "                    validation_data=test_generator,\n",
    "                    epochs = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss, acc = model.evaluate(X_dev, Y_dev)\n",
    "print(\"Dev set accuracy = \", acc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Real Time?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_triggerword(filename):\n",
    "    plt.subplot(2, 1, 1)\n",
    "\n",
    "    x = graph_spectrogram(filename)\n",
    "    # the spectogram outputs (freqs, Tx) and we want (Tx, freqs) to input into the model\n",
    "    x  = x.swapaxes(0,1)\n",
    "    x = np.expand_dims(x, axis=0)\n",
    "    predictions = model.predict(x)\n",
    "    \n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(predictions[0,:,0])\n",
    "    plt.ylabel('probability')\n",
    "    plt.show()\n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chime_file = \"audio_examples/chime.wav\"\n",
    "def chime_on_activate(filename, predictions, threshold):\n",
    "    audio_clip = AudioSegment.from_wav(filename)\n",
    "    chime = AudioSegment.from_wav(chime_file)\n",
    "    Ty = predictions.shape[1]\n",
    "    # Step 1: Initialize the number of consecutive output steps to 0\n",
    "    consecutive_timesteps = 0\n",
    "    # Step 2: Loop over the output steps in the y\n",
    "    for i in range(Ty):\n",
    "        # Step 3: Increment consecutive output steps\n",
    "        consecutive_timesteps += 1\n",
    "        # Step 4: If prediction is higher than the threshold and more than 75 consecutive output steps have passed\n",
    "        if predictions[0,i,0] > threshold and consecutive_timesteps > 75:\n",
    "            # Step 5: Superpose audio and background using pydub\n",
    "            audio_clip = audio_clip.overlay(chime, position = ((i / Ty) * audio_clip.duration_seconds)*1000)\n",
    "            # Step 6: Reset consecutive output steps to 0\n",
    "            consecutive_timesteps = 0\n",
    "        \n",
    "    audio_clip.export(\"chime_output.wav\", format='wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"./raw_data/dev/1.wav\"\n",
    "prediction = detect_triggerword(filename)\n",
    "chime_on_activate(filename, prediction, 0.5)\n",
    "IPython.display.Audio(\"./chime_output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocess the audio to the correct format\n",
    "def preprocess_audio(filename):\n",
    "    # Trim or pad audio segment to 10000ms\n",
    "    padding = AudioSegment.silent(duration=10000)\n",
    "    segment = AudioSegment.from_wav(filename)[:10000]\n",
    "    segment = padding.overlay(segment)\n",
    "    # Set frame rate to 44100\n",
    "    segment = segment.set_frame_rate(44100)\n",
    "    # Export as wav\n",
    "    segment.export(filename, format='wav')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Once you've uploaded your audio file to Coursera, put the path to your file in the variable below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "your_filename = \"audio_examples/my_audio.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preprocess_audio(your_filename)\n",
    "IPython.display.Audio(your_filename) # listen to the audio you uploaded "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, use the model to predict when you say activate in the 10 second audio clip, and trigger a chime. If beeps are not being added appropriately, try to adjust the chime_threshold."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chime_threshold = 0.5\n",
    "prediction = detect_triggerword(your_filename)\n",
    "chime_on_activate(your_filename, prediction, chime_threshold)\n",
    "IPython.display.Audio(\"./chime_output.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "nlp-sequence-models",
   "graded_item_id": "rSupZ",
   "launcher_item_id": "cvGhe"
  },
  "kernelspec": {
   "display_name": "pytube",
   "language": "python",
   "name": "pytube"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
